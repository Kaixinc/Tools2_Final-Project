{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy.stats import kendalltau\n",
    "from ast import literal_eval\n",
    "import timeit\n",
    "\n",
    "Questions, Dataset and motivation section:\n",
    "\n",
    "Motivation:\n",
    "\n",
    "League of legends is a multiplayer online battle arena video game developed and published by Riot Games which is one of the most popular game in the earth right now.The professional league is very exciting to watch that the 2018 League of Legends World Finals had nearly 100 million viewers. In the opposite, those presenters make poor predictions or ambiguous judgements on leads which gave views misleading on game real-time analysis all-time. Our goal is to dig deep in game real-time data, not only on the gold difference on two team but based on all other datas to predict the result of game, give viewers direct and precise feedback on real-time professional league game. This project could be further developed to website or tool to do function like real-time game analysis which all major analysis webside does not provide.\n",
    "\n",
    "Questions:\n",
    "Should team focus choose late game comp or early game comp on champion select in general based on winrate analysis?\n",
    "\n",
    "If had a chance, should the team choose to destroy object, eliminate neutral monster or kill enemy players?\n",
    "\n",
    "If we want to enjoy an entire series of game(best-of-five-sets format), how long does it take usual? We have to find the game length distributions.\n",
    "\n",
    "DataSet:\n",
    "Data set come from kaggle. Total 8 dataset and main dataset with 7620 rows and 58 columns. Contains all game in side status on each minutes from professional league game between 2015-2018 in the world. \n",
    "\n",
    "Input and Output:\n",
    "Input is the game data after we transformate for model use, Output would be series of analysis graph and the blue team result(win or lose).\n",
    "\n",
    "matchinfo = pd.read_csv('leagueoflegends/LeagueofLegends.csv')\n",
    "gold = pd.read_csv('leagueoflegends/gold.csv')\n",
    "kills = pd.read_csv('leagueoflegends/kills.csv')\n",
    "info = pd.read_csv('leagueoflegends/matchinfo.csv')\n",
    "structures = pd.read_csv('leagueoflegends/structures.csv')\n",
    "monsters = pd.read_csv('leagueoflegends/monsters.csv')\n",
    "columns = pd.read_csv('leagueoflegends/_columns.csv')\n",
    "\n",
    "Detailed main data column element introduction:\n",
    "\n",
    "columns\n",
    "\n",
    "matchinfo.head(5)\n",
    "\n",
    "matchinfo.to_pickle(\"leagueoflegends/match.pkl\")\n",
    "\n",
    "Save main data to pickle.\n",
    "\n",
    "df = pd.read_pickle(\"leagueoflegends/match.pkl\")\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.head()\n",
    "\n",
    "Main data datatypes:\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "df.isnull().any()\n",
    "\n",
    "Quality of cleaning:\n",
    "1.Data Cleaning and type conversion activity:\n",
    "\n",
    "We noticed that few columns are certain list attribute for each team(column 10-24 in our data frame). we should change the dtype of them. Also, because these attributes are list of minutes, it should has the length which is less than the value of game length or exactly the value of gamelength, we should check if that is the thing.\n",
    "\n",
    "\n",
    "2.Missed value:\n",
    "on column like Blue/Red Top,mid,Bottom, Support,Jungle, which is the role of the game and it contains player name and Blue/Red team tag. We would ignore it first because it is not the data we looking for this project. Detailed data cleaning activity were introduced on each section of data transformation below on each section.\n",
    "\n",
    "3.Data summary statistics and interpretation.\n",
    "on the end of data section.\n",
    "\n",
    "\n",
    "df[['gamelength', 'bKills']].head(4)\n",
    "\n",
    "len(df['golddiff'][0])\n",
    "\n",
    "type(df['bKills'][0])\n",
    "\n",
    "df['golddiff'] = df['golddiff'].apply(literal_eval)\n",
    "df['goldblue'] = df['goldblue'].apply(literal_eval)\n",
    "df['bKills'] = df['bKills'].apply(literal_eval)\n",
    "df['bTowers'] = df['bTowers'].apply(literal_eval)\n",
    "df['bInhibs'] = df['bInhibs'].apply(literal_eval)\n",
    "df['bDragons'] = df['bDragons'].apply(literal_eval)\n",
    "df['bBarons'] = df['bBarons'].apply(literal_eval)\n",
    "df['bHeralds'] = df['bHeralds'].apply(literal_eval)\n",
    "df['goldred'] = df['goldred'].apply(literal_eval)\n",
    "df['rKills'] = df['rKills'].apply(literal_eval)\n",
    "df['rTowers'] = df['rTowers'].apply(literal_eval)\n",
    "df['rInhibs'] = df['rInhibs'].apply(literal_eval)\n",
    "df['rDragons'] = df['rDragons'].apply(literal_eval)\n",
    "df['rBarons'] = df['rBarons'].apply(literal_eval)\n",
    "df['rHeralds'] = df['rHeralds'].apply(literal_eval)\n",
    "df['goldblueTop'] = df['goldblueTop'].apply(literal_eval)\n",
    "df['goldblueJungle'] = df['goldblueJungle'].apply(literal_eval)\n",
    "df['goldblueMiddle'] = df['goldblueMiddle'].apply(literal_eval)\n",
    "df['goldblueADC'] = df['goldblueADC'].apply(literal_eval)\n",
    "df['goldblueSupport'] = df['goldblueSupport'].apply(literal_eval)\n",
    "df['goldredTop'] = df['goldredTop'].apply(literal_eval)\n",
    "df['goldredJungle'] = df['goldredJungle'].apply(literal_eval)\n",
    "df['goldredMiddle'] = df['goldredMiddle'].apply(literal_eval)\n",
    "df['goldredADC'] = df['goldredADC'].apply(literal_eval)\n",
    "df['goldredSupport'] = df['goldredSupport'].apply(literal_eval)\n",
    "\n",
    "Seems like gold diff is str. It should be the same situation other column data has, apply literal_eval function on those columns to fix it.\n",
    "\n",
    "len(df['golddiff'][0])\n",
    "\n",
    "len(df['bKills'][0])\n",
    "\n",
    "type(df['bKills'][0])\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "Game length distribution analysis below:\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "colors = sns.color_palette('hls', 8)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,14))\n",
    "fig.suptitle('Game Length Distributions', fontsize=24)\n",
    "fig.subplots_adjust(top=0.9)\n",
    "percentiles = np.array([25, 50, 75])\n",
    "ptiles_gl = np.percentile(df['gamelength'], percentiles)\n",
    "p1 = plt.subplot2grid((2,4), (0,0), colspan=1)\n",
    "sns.boxplot(y=df['gamelength'], color=colors[5])\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylabel('Minutes', fontsize = 18, fontweight = 'bold')\n",
    "\n",
    "\n",
    "p2 = plt.subplot2grid((2,4), (0,1), colspan=3)\n",
    "x = np.sort(df['gamelength'])\n",
    "y = np.arange(1, len(x) + 1) / len(x)\n",
    "plt.plot(x,y, marker='.', linestyle='none', color=colors[5])\n",
    "plt.plot(ptiles_gl, percentiles/100, marker='D', color='red', linestyle='none')\n",
    "yvals = p2.get_yticks()\n",
    "p2.set_yticklabels(['{:3.0f}%'.format(y*100) for y in yvals])\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(np.arange(0, 85, 5), fontsize=14)\n",
    "plt.xlabel('Minutes', fontsize=18, fontweight = 'bold')\n",
    "plt.ylabel('Percentage', fontsize=18, fontweight='bold')\n",
    "plt.annotate('25% of games less than 32 minutes', xy=(32, .25), xytext=(37, .23), fontsize=18, \n",
    "             arrowprops=dict(facecolor='black'))\n",
    "plt.annotate('50% of games less than 37 minutes', xy=(37, .5), xytext=(42, .48), \n",
    "             fontsize=18, arrowprops=dict(facecolor='black'))\n",
    "plt.annotate('75% of games less than 42 minutes', xy=(42, .75), xytext=(47, .73), fontsize=18, \n",
    "             arrowprops=dict(facecolor='black'))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "We find that about 50% game ends between 32 and 42 minuteswhich we has very less game ending early than 20 minutes or late than 60 minutes, we would use those facts for our future data analysis. It help us to figure out the data distribution too because all data were based on minutes ie. game time.\n",
    "\n",
    "df['golddiff']\n",
    "\n",
    "Gold difference vs winrate analysis:\n",
    "\n",
    "we made a new data frame which stores only minute(real-time game length), Gold lead(Blue team) and the winrate based on the gold lead and the the game length on that time. Gold lead was calculated from the gold diff column , we made it from -10000 to 10000 with interval 500. Minute from 0 to 60 minutes with interval 5 to generate a heatmap on real-time gold difference and win-rate. Also three graph on early game(Minute <20),middle game(<20minute<40) and late game (40<minute<60)\n",
    "\n",
    "dy = 500\n",
    "dx = 5\n",
    "df2= []\n",
    "for index, row in df.iterrows():\n",
    "    gdiff= [10000 if a > 10000 else -10000 if a < -10000 else int(int(a/dy)*dy) for a in row.golddiff]\n",
    "    m= min(60+1,len(gdiff))        \n",
    "    if row.bResult==1:\n",
    "        for g in range(1, m): df2.append([int(int((g-1)/dx)*dx+dx), gdiff[g], 1])\n",
    "        for g in range(1, m): df2.append([int(int((g-1)/dx)*dx+dx), -gdiff[g], 0])      \n",
    "    elif row.rResult==1: \n",
    "        for g in range(1, m): df2.append([int(int((g-1)/dx)*dx+dx), -gdiff[g], 1])\n",
    "        for g in range(1, m): df2.append([int(int((g-1)/dx)*dx+dx), gdiff[g], 0])\n",
    "    else: print('Bad result'); continue  \n",
    "df2= pd.DataFrame(df2); df2.columns= ['Time (min)', 'Gold Lead', 'Win Percent']\n",
    "\n",
    "numgames= [int(x/10) for x in df2.groupby(['Time (min)']).size().reset_index(name='counts')['counts']]\n",
    "df2= df2.groupby(['Time (min)', 'Gold Lead']).apply(lambda x: x['Win Percent'].sum()/len(x)).reset_index(name='Win Percent')\n",
    "df2['Win Percent']= df2['Win Percent'].map(lambda x: int(x*100))\n",
    "df3 = df2\n",
    "df2= df2.pivot('Gold Lead', 'Time (min)', 'Win Percent') # GRAPH HEAT MAP\n",
    "yticknames=['' if (k/500)%2==1 else str(int(k/1000.0))+'k' for k in range(-10000,10000+1,int(dy))]\n",
    "\n",
    "\n",
    "df3\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(40,36))\n",
    "fig.suptitle('Gold lead Winpercent Analysis', x=0.065, y=1.03, fontsize=24, fontweight='bold', \n",
    "             horizontalalignment='left')\n",
    "fig.subplots_adjust(top=0.9)\n",
    "\n",
    "percentiles = np.array([25, 50, 75])\n",
    "ptiles_gl = np.percentile(df['gamelength'], percentiles)\n",
    "\n",
    "plots = plt.subplot2grid((2,3), (0,0), colspan=1)\n",
    "sns.heatmap(df2, vmin=0, vmax=100, yticklabels=yticknames, ax=plots, annot=True, cbar=False, fmt='g', cmap='viridis').invert_yaxis()\n",
    "ax2= plots.twiny()\n",
    "ax2.set_xlim(plots.get_xlim())\n",
    "ax2.set_xticks([x+0.5 for x in range(int(dx/2),60,int(dx))]+[60])\n",
    "ax2.set_xticklabels([int(x) for x in numgames])\n",
    "ax2.set_xlabel(r'Number of Games')\n",
    "ax2.grid(False)\n",
    "\n",
    "plot2= plt.subplot2grid((2,3), (0,1), colspan=1)\n",
    "plt.title('earlygame')\n",
    "sns.barplot(x = df3['Gold Lead'][df3['Time (min)'].between(0, 32, inclusive=False)], y= df3['Win Percent'][df3['Time (min)'].between(0, 32, inclusive=False)])\n",
    "plt.xticks(rotation='vertical',fontsize=10)\n",
    "plot3= plt.subplot2grid((2,3), (1,0), colspan=1)\n",
    "plt.title('middlegame')\n",
    "sns.barplot(x = df3['Gold Lead'][df3['Time (min)'].between(32, 42, inclusive=False)], y= df3['Win Percent'][df3['Time (min)'].between(32, 42, inclusive=False)])\n",
    "plt.xticks(rotation='vertical',fontsize=10)\n",
    "plot4= plt.subplot2grid((2,3), (1,1), colspan=1)\n",
    "plt.title('lategame')\n",
    "sns.barplot(x = df3['Gold Lead'][df3['Time (min)'].between(42, 60, inclusive=False)], y= df3['Win Percent'][df3['Time (min)'].between(42, 60, inclusive=False)])\n",
    "plt.xticks(rotation='vertical',fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "We choose only data from 0 to 60 minutes because we find that very few games end after 60 minutes by game length analysis above.\n",
    "Observation on gold diff on time vs winrate:\n",
    "1.Gold is the direct attribute to reflect Leads\n",
    "2.Importance of gold lead(gold diff) between two game become less as game length increase, but doesn’t fall off much.\n",
    "3.Team with big gold lead in early period tends to win game straightly.\n",
    "\n",
    "Conclusion: Early game > Late game\n",
    "\n",
    "df.to_pickle(\"leagueoflegends/modified.pkl\")\n",
    "\n",
    "model = pd.read_pickle(\"leagueoflegends/modified.pkl\")\n",
    "\n",
    "matchinfo = pd.read_csv('leagueoflegends/LeagueofLegends.csv')\n",
    "gold = pd.read_csv('leagueoflegends/gold.csv')\n",
    "kills = pd.read_csv('leagueoflegends/kills.csv')\n",
    "info = pd.read_csv('leagueoflegends/matchinfo.csv')\n",
    "structures = pd.read_csv('leagueoflegends/structures.csv')\n",
    "monsters = pd.read_csv('leagueoflegends/monsters.csv')\n",
    "columns = pd.read_csv('leagueoflegends/_columns.csv')\n",
    "\n",
    "We now using in-game data beside gold diffence and see how our model works on those data only. Instead of main dataset we would use more detailed data from other dataset and using address as our key for data reduction and transformation. We add a new column id which based on address column which is the website we could find the match data to match data on each game.\n",
    "\n",
    "model['id'] = model['Address'].astype(str).str[-16:]\n",
    "kills['id'] = kills['Address'].astype(str).str[-16:]\n",
    "monsters['id'] = monsters['Address'].astype(str).str[-16:]\n",
    "structures['id'] = structures['Address'].astype(str).str[-16:]\n",
    "model.head()\n",
    "\n",
    "monsters['Type'].unique()\n",
    "\n",
    "Dragon was updated to Water ,Wind , Earth and Fire dragon after patch 6.9(2016 preseason), There is 5 column count for dragon now while one is expire. Have to clean those from our dataset.\n",
    "\n",
    "old_dragon_id = monsters[ monsters['Type']==\"DRAGON\"]['id'].unique()\n",
    "old_dragon_id\n",
    "\n",
    "monsters = monsters[ ~monsters['id'].isin(old_dragon_id)]\n",
    "monsters[monsters['Type']==\"DRAGON\"]\n",
    "\n",
    "Same with kill.\n",
    "\n",
    "kills = kills[ ~kills['id'].isin(old_dragon_id)]\n",
    "kills = kills[ kills['Time']>0]\n",
    "\n",
    "kills['Minute'] = kills['Time'].astype(int)\n",
    "\n",
    "kills['Team'] = np.where( kills['Team']==\"rKills\",\"Red\",\"Blue\")\n",
    "kills.head()\n",
    "\n",
    "f = {'Time':['mean','count']}\n",
    "\n",
    "killsGrouped = kills.groupby( ['id','Team','Minute'] ).agg(f).reset_index()\n",
    "killsGrouped.columns = ['id','Team','Minute','Time Avg','Count']\n",
    "killsGrouped = killsGrouped.sort_values(by=['id','Minute'])\n",
    "killsGrouped.head(13)\n",
    "\n",
    "choose only the data we need for future use.\n",
    "\n",
    "Change datatype in structure and modify team column as the type we have in previous dataframe.\n",
    "\n",
    "structures = structures[ ~structures['id'].isin(old_dragon_id)]\n",
    "structures = structures[ structures['Time']>0]\n",
    "\n",
    "structures['Minute'] = structures['Time'].astype(int)\n",
    "structures['Team'] = np.where(structures['Team']==\"bTowers\",\"Blue\",\n",
    "                        np.where(structures['Team']==\"binhibs\",\"Blue\",\"Red\"))\n",
    "structures2 = structures.sort_values(by=['id','Minute'])\n",
    "structures2.head(13)\n",
    "\n",
    "kills_structures = killsGrouped.merge(structures2[['id','Minute','Team','Time','Lane','Type']],\n",
    "                                      on=['id','Minute','Team'],how='outer')\n",
    "kills_structures.head(20)\n",
    "\n",
    "merge kill and structure dataframe,we would do data cleaning latter.\n",
    "\n",
    "monsters = monsters[ ~monsters['id'].isin(old_dragon_id)]\n",
    "monsters['Type2'] = np.where( monsters['Type']==\"FIRE_DRAGON\", \"DRAGON\",\n",
    "                    np.where( monsters['Type']==\"EARTH_DRAGON\",\"DRAGON\",\n",
    "                    np.where( monsters['Type']==\"WATER_DRAGON\",\"DRAGON\",       \n",
    "                    np.where( monsters['Type']==\"AIR_DRAGON\",\"DRAGON\",   \n",
    "                             monsters['Type']))))\n",
    "\n",
    "monsters = monsters[ monsters['Time']>0]\n",
    "\n",
    "monsters['Minute'] = monsters['Time'].astype(int)\n",
    "\n",
    "monsters['Team'] = np.where( monsters['Team']==\"bDragons\",\"Blue\",\n",
    "                   np.where( monsters['Team']==\"bHeralds\",\"Blue\",\n",
    "                   np.where( monsters['Team']==\"bBarons\", \"Blue\", \n",
    "                           \"Red\")))\n",
    "\n",
    "\n",
    "\n",
    "monsters.head()\n",
    "\n",
    "kills_structures_monsters = kills_structures.merge(monsters[['id','Minute','Team','Time','Type2']], on=['id','Minute'],how='outer')\n",
    "kills_structures_monsters = kills_structures_monsters.sort_values(by=['id','Minute'])\n",
    "kills_structures_monsters.head(5)\n",
    "\n",
    "merge all dataframe into one.\n",
    "\n",
    "\n",
    "stackedData = killsGrouped.append(structures2)\n",
    "stackedData = stackedData.append(monsters[['id','Address','Team','Minute','Time','Type2']])\n",
    "\n",
    "stackedData['Time2'] = stackedData['Time'].fillna(stackedData['Time Avg'])\n",
    "\n",
    "stackedData = stackedData.sort_values(by=['id','Time2'])\n",
    "\n",
    "stackedData['EventNum'] = stackedData.groupby('id').cumcount()+1\n",
    "\n",
    "stackedData = stackedData[['id','EventNum','Team','Minute','Time2','Count','Type','Lane','Type2']]\n",
    "\n",
    "stackedData.columns = ['id','EventNum','Team','Minute','Time','KillCount','StructType','StructLane','Monster']\n",
    "\n",
    "stackedData.head(5)\n",
    "\n",
    "stackedData['Event'] = np.where(stackedData['KillCount']>0,\"KILLS\",None)\n",
    "stackedData['Event'] = stackedData['Event'].fillna(stackedData['StructType'])\n",
    "stackedData['Event'] = stackedData['Event'].fillna(stackedData['Monster'])\n",
    "\n",
    "                        \n",
    "\n",
    "stackedData.head(10)\n",
    "\n",
    "By transformation We now have dataframe contains type of structure, monter and event classification on event column and count event number on Eventnum column. We now have to change them to int format for our model train by using cumcount on each group with same team and same time column which contains the string in same type of events.\n",
    "\n",
    "stackedData.to_pickle(\"leagueoflegends/stacked.pkl\")\n",
    "\n",
    "stackedDatas = pd.read_pickle(\"leagueoflegends/stacked.pkl\")\n",
    "\n",
    "stackedDatas = stackedData.sort_values(by=['id','Minute'])\n",
    "\n",
    "stackedDatas = stackedDatas.set_index(np.arange(len(stackedDatas.index)))\n",
    "\n",
    "stackedDatas['Blue_Kill_count'] = stackedDatas[(stackedDatas['Event'].str.contains('KILL'))&(stackedDatas['Team'].str.contains('Blue'))].groupby(['Team','id']).cumcount()+1\n",
    "stackedDatas['Blue_Object_count'] = stackedDatas[(stackedDatas['Event'].str.contains('TURRET'))&(stackedDatas['Team'].str.contains('Blue'))].groupby(['Team','id']).cumcount()+1\n",
    "stackedDatas['Blue_Monster_count'] = stackedDatas[(stackedDatas['Event'].str.contains('DRAGON|HERALD|BARON'))&(stackedDatas['Team'].str.contains('Blue'))].groupby(['Team','id']).cumcount()+1\n",
    "stackedDatas['Red_Kill_count'] = stackedDatas[(stackedDatas['Event'].str.contains('KILL'))&(stackedDatas['Team'].str.contains('Red'))].groupby(['Team','id']).cumcount()+1\n",
    "stackedDatas['Red_Object_count'] = stackedDatas[(stackedDatas['Event'].str.contains('TURRET'))&(stackedDatas['Team'].str.contains('Red'))].groupby(['Team','id']).cumcount()+1\n",
    "stackedDatas['Red_Monster_count'] = stackedDatas[(stackedDatas['Event'].str.contains('DRAGON|HERALD|BARON'))&(stackedDatas['Team'].str.contains('Red'))].groupby(['Team','id']).cumcount()+1\n",
    "\n",
    "stackedDatas\n",
    "\n",
    "Have so may missing value on our final dataset, we fill those data by group of same id using ffill function, finally fill those nan value with 0 because the missing value is the count which the event has not happened yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
